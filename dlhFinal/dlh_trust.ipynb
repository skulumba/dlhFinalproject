{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZRUJFOJV9Po"
   },
   "source": [
    "<h1>Generate Mistrust Scores for All Patients</h1>\n",
    "- Supervised Machine Learning (binary chartevents features) to predict whether \"noncompliance\" appears in the notes\n",
    "- Supervised Machine Learning (binary chartevents features) to predict whether the patient or family consents/declines autopsy\n",
    "- Off the shelf sentiment analysis of the notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2011,
     "status": "ok",
     "timestamp": 1746052238162,
     "user": {
      "displayName": "Saad K",
      "userId": "05204663833745186935"
     },
     "user_tz": 420
    },
    "id": "7BCpazbiV9Pq"
   },
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 1️⃣ Import libraries\n",
    "# ===================================\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import pickle as pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tqdm\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1422VjOfV9Pr"
   },
   "outputs": [],
   "source": [
    "# =================================\n",
    "# 2️⃣ Connect to MIMIC-III database\n",
    "# =================================\n",
    "con = psycopg2.connect(dbname ='mimic', user='saadtech', host=\"/var/run/postgresql\")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwMjiCOtV9Ps"
   },
   "source": [
    "<h1>Load Data from MIMIC</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Nj3zBpQ5V9Ps",
    "outputId": "26175ced-3eb0-444f-fba1-5c6760a81ccb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 09:24:53\n",
      "2025-05-05 09:25:39\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3️⃣ Read interpersonal interaction variables from chartevents\n",
    "# ============================================================\n",
    "relevant_labels = '''\n",
    "Family Communication\n",
    "Follows Commands\n",
    "Education Barrier\n",
    "Education Learner\n",
    "Education Method\n",
    "Education Readiness\n",
    "Education Topic #1\n",
    "Education Topic #2\n",
    "Pain\n",
    "Pain Level\n",
    "Pain Level (Rest)\n",
    "Pain Assess Method\n",
    "Restraint\n",
    "Restraint Type\n",
    "Restraint (Non-violent)\n",
    "Restraint Ordered (Non-violent)\n",
    "Restraint Location\n",
    "Reason For Restraint\n",
    "Spiritual Support\n",
    "Support Systems\n",
    "State\n",
    "Behavior\n",
    "Behavioral State\n",
    "Reason For Restraint\n",
    "Stress\n",
    "Safety\n",
    "Safety Measures_U_1\n",
    "Family\n",
    "Patient/Family Informed\n",
    "Pt./Family Informed\n",
    "Health Care Proxy\n",
    "BATH\n",
    "bath\n",
    "Bath\n",
    "Bed Bath\n",
    "bed bath\n",
    "bed bath\n",
    "Bedbath\n",
    "CHG Bath\n",
    "Skin Care\n",
    "Judgement\n",
    "Family Meeting held\n",
    "Emotional / physical / sexual harm by partner or close relation\n",
    "Verbal Response\n",
    "Side Rails\n",
    "Orientation\n",
    "RSBI Deferred\n",
    "Richmond-RAS Scale\n",
    "Riker-SAS Scale\n",
    "Status and Comfort\n",
    "Teaching directed toward\n",
    "Consults\n",
    "Social work consult\n",
    "Sitter\n",
    "security\n",
    "safety\n",
    "headache\n",
    "hairwashed\n",
    "observer\n",
    "'''\n",
    "\n",
    "matches_text = []\n",
    "for rl in relevant_labels.split('\\n'):\n",
    "    rl = rl.strip()\n",
    "    if len(rl):\n",
    "        matches_text.append( \"LOWER(label) LIKE '%%%s%%'\" % rl.lower())\n",
    "matches = ' or '.join(matches_text)\n",
    "\n",
    "print strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "\n",
    "chartevents_query = 'select distinct hadm_id,label,value from mimiciii.chartevents c JOIN mimiciii.d_items i on i.itemid=c.itemid where (%s)' % matches\n",
    "chartevents = pd.read_sql_query(chartevents_query, con)\n",
    "\n",
    "print strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "\n",
    "#chartevents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5uAou3T1V9Pt",
    "outputId": "bf18eab1-9226-4c45-e1f1-b5b543f0973e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 09:25:45\n",
      "2025-05-05 09:28:16\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 4️⃣ Load clinical notes\n",
    "# =========================================\n",
    "print strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "notes_query = \\\n",
    "\"\"\"\n",
    "select distinct n.hadm_id,n.category,n.text,n.chartdate,n.charttime\n",
    "from mimiciii.noteevents n\n",
    "where iserror IS NULL --this is null in mimic 1.4, rather than empty space\n",
    "and hadm_id IS NOT NULL\n",
    ";\n",
    "\"\"\"\n",
    "notes = pd.read_sql_query(notes_query, con)\n",
    "print strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goi3YACxV9Pu"
   },
   "source": [
    "<h1> Extract Features and Labels</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iek3x9myV9Pu",
    "outputId": "9b8ff641-0ec6-4509-e351-744a163fa74f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54510/54510 [08:28<00:00, 107.19it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================================\n",
    "# 5️⃣ Extract features from chartevents\n",
    "# =========================================\n",
    "chartevents_features = {}\n",
    "for hadm_id,rows in tqdm.tqdm(chartevents.groupby('hadm_id')):\n",
    "    feats = {}\n",
    "    for i,row in rows.iterrows():\n",
    "        label = row.label.lower()\n",
    "\n",
    "        if row.value is None:\n",
    "            val = 'none'\n",
    "        else:\n",
    "            val = row.value.lower()\n",
    "\n",
    "        if 'reason for restraint' in label:\n",
    "            if (val == 'not applicable') or (val == 'none'):\n",
    "                val = 'none'\n",
    "            elif ('threat' in val) or ('acute risk of' in val):\n",
    "                val = 'threat of harm'\n",
    "            elif ('confusion' in val) or ('delirium' in val) or (val == 'impaired judgment') or (val == 'sundowning'):\n",
    "                val = 'confusion/delirium'\n",
    "            elif ('occurence' in val) or (val == 'severe physical agitation') or (val == 'violent/self des'):\n",
    "                val = 'prescence of violence'\n",
    "            elif (val == 'ext/txinterfere') or (val == 'protection of lines and tubes') or (val == 'treatment interference'):\n",
    "                val = 'treatment interference'\n",
    "            elif 'risk for fall' in val:\n",
    "                val = 'risk for falls'\n",
    "            else:\n",
    "                val = val\n",
    "            feats[('reason for restraint', val)] = 1\n",
    "\n",
    "        elif 'restraint location' in label:\n",
    "            if val == 'none':\n",
    "                val = 'none'\n",
    "            elif '4 point rest' in val:\n",
    "                val = '4 point restraint'\n",
    "            else:\n",
    "                val = 'some restraint'\n",
    "            feats[('restraint location', val)] = 1\n",
    "\n",
    "        elif 'restraint device' in label:\n",
    "\n",
    "            if 'sitter' in val:\n",
    "                val = 'sitter'\n",
    "            elif 'limb' in val:\n",
    "                val = 'limb'\n",
    "            else:\n",
    "                val = val\n",
    "            feats[('restraint device', val)] = 1\n",
    "\n",
    "        elif 'bath' in label:\n",
    "            if 'part' in label:\n",
    "                val = 'partial'\n",
    "            elif 'self' in val:\n",
    "                val = 'self'\n",
    "            elif 'refused' in val:\n",
    "                val = 'refused'\n",
    "            elif 'shave' in val:\n",
    "                val = 'shave'\n",
    "            elif 'hair' in val:\n",
    "                val = 'hair'\n",
    "            elif 'none' in val:\n",
    "                val = 'none'\n",
    "            else:\n",
    "                val = 'done'\n",
    "            feats[('bath', val)] = 1\n",
    "\n",
    "        elif label in ['behavior', 'behavioral state']:\n",
    "            #feats[('behavior', val)] = 1\n",
    "            pass\n",
    "\n",
    "        elif label.startswith('pain level'):\n",
    "            feats[('pain level', val)] = 1\n",
    "\n",
    "        elif label.startswith('pain management'):\n",
    "            #feats[('pain management', val)] = 1\n",
    "            pass\n",
    "        elif label.startswith('pain type'):\n",
    "            #feats[('pain type', val)] = 1\n",
    "            pass\n",
    "        elif label.startswith('pain cause'):\n",
    "            #feats[('pain cause', val)] = 1\n",
    "            pass\n",
    "        elif label.startswith('pain location'):\n",
    "            #feats[('pain location', val)] = 1\n",
    "            pass\n",
    "\n",
    "        elif label.startswith('education topic'):\n",
    "            feats[('education topic', val)] = 1\n",
    "\n",
    "        elif label.startswith('safety measures'):\n",
    "            feats[('safety measures', val)] = 1\n",
    "\n",
    "        elif label.startswith('side rails'):\n",
    "            feats[('side rails', val)] = 1\n",
    "\n",
    "        elif label.startswith('status and comfort'):\n",
    "            feats[('status and comfort', val)] = 1\n",
    "\n",
    "        elif 'informed' in label:\n",
    "            feats[('informed', val)] = 1\n",
    "        else:\n",
    "\n",
    "            if type(row.value) == type(''):\n",
    "                # extract phrase\n",
    "                featname = (row.label.lower(), row.value.lower())\n",
    "                value = 1.0\n",
    "                feats[featname] = value\n",
    "            elif row.value is None:\n",
    "                featname = (row.label.lower(),'none')\n",
    "                value = 1.0\n",
    "                feats[featname] = value\n",
    "            else:\n",
    "                featname = (row.label.lower(),)\n",
    "                value = value\n",
    "                feats[featname] = value\n",
    "                pass\n",
    "    chartevents_features[hadm_id] = feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zvI5HgW7V9Pv",
    "outputId": "13e69339-ba5c-40f6-e52e-7b4fc0f6e7f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58361/58361 [00:27<00:00, 2158.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patients labeled as    trustful: 54030\n",
      "patients labeled as mistrustful: 484\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 6️⃣ LABEL: noncompliance in notes\n",
    "# =========================================\n",
    "\n",
    "mistrust_ids = []\n",
    "for hadm_id,rows in tqdm.tqdm(notes.groupby('hadm_id')):\n",
    "    # This is customizable to various note-based definitions of what to look for\n",
    "    mistrust = False\n",
    "    for text in rows.text.values:\n",
    "        if 'noncompliant' in text.lower():\n",
    "            mistrust = True\n",
    "\n",
    "    # add the ID\n",
    "    if mistrust:\n",
    "        mistrust_ids.append(hadm_id)\n",
    "\n",
    "# binary labels\n",
    "trust_labels_noncompliance = {hadm_id:'trust' for hadm_id in chartevents['hadm_id'].values}\n",
    "for hadm_id in mistrust_ids:\n",
    "    trust_labels_noncompliance[int(hadm_id)] = 'mistrust'\n",
    "\n",
    "print 'patients labeled as    trustful:', len([y for y in trust_labels_noncompliance.values() if y=='trust'   ])\n",
    "print 'patients labeled as mistrustful:', len([y for y in trust_labels_noncompliance.values() if y=='mistrust'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "U4XZI3i-V9Pv",
    "outputId": "e11efb61-479d-4b24-ee1a-81fc53cc1588"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58361/58361 [00:42<00:00, 1381.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patients labeled as    trustful: 739\n",
      "patients labeled as mistrustful: 270\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# LABEL: whether patient got autopsy\n",
    "# =========================================\n",
    "\n",
    "autopsy_consent = []\n",
    "autopsy_decline = []\n",
    "for hadm_id,rows in tqdm.tqdm(notes.groupby('hadm_id')):\n",
    "    consented = False\n",
    "    declined = False\n",
    "    for text in rows.text.values:\n",
    "        for line in text.lower().split('\\n'):\n",
    "            if 'autopsy' in line:\n",
    "                if 'decline' in line:\n",
    "                    declined = True\n",
    "                if 'not consent' in line:\n",
    "                    declined = True\n",
    "                if 'refuse' in line:\n",
    "                    declined = True\n",
    "                if 'denied' in line:\n",
    "                    declined = True\n",
    "\n",
    "                if 'consent' in line:\n",
    "                    consented = True\n",
    "                if 'agree' in line:\n",
    "                    consented = True\n",
    "                if 'request' in line:\n",
    "                    consented = True\n",
    "\n",
    "    # probably some \"declined donation but consented to autopsy\" or something confusing. just ignore hard cases\n",
    "    if consented and declined:\n",
    "        continue\n",
    "\n",
    "    if consented:\n",
    "        autopsy_consent.append(hadm_id)\n",
    "    if declined:\n",
    "        autopsy_decline.append(hadm_id)\n",
    "\n",
    "# binary labels\n",
    "trust_labels_autopsy = {}\n",
    "for hadm_id in autopsy_consent:\n",
    "    trust_labels_autopsy[int(hadm_id)] = 'mistrust'\n",
    "for hadm_id in autopsy_decline:\n",
    "    trust_labels_autopsy[int(hadm_id)] = 'trust'\n",
    "\n",
    "print 'patients labeled as    trustful:', len([y for y in trust_labels_autopsy.values() if y=='trust'   ])\n",
    "print 'patients labeled as mistrustful:', len([y for y in trust_labels_autopsy.values() if y=='mistrust'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VSrBZBuV9Pw"
   },
   "source": [
    "<h1>Supervised Learning to Classify Trust-based Outcomes</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8yFs4xRkV9Pw"
   },
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# Useful ML functions\n",
    "# =========================================\n",
    "def data_split(ids, ratio=0.7):\n",
    "    random.shuffle(ids)\n",
    "    train = ids[:int(len(ids)*ratio) ]\n",
    "    test  = ids[ int(len(ids)*ratio):]\n",
    "    return train, test\n",
    "\n",
    "def compute_stats(task, pred, P, ref, labels_map):\n",
    "    scores = P[:,1] - P[:,0]\n",
    "    res = compute_stats_binary(    task, pred, scores, ref, labels_map)\n",
    "    return res\n",
    "\n",
    "def compute_stats_binary(task, pred, P, ref, labels):\n",
    "    # santiy check\n",
    "    assert all(map(int,P>0) == pred)\n",
    "\n",
    "    V = [0,1]\n",
    "    n = len(V)\n",
    "    assert n==2, 'sorry, must be exactly two labels (how else would we do AUC?)'\n",
    "    conf = np.zeros((n,n), dtype='int32')\n",
    "    for p,r in zip(pred,ref):\n",
    "        conf[p][r] += 1\n",
    "\n",
    "    print conf\n",
    "    print\n",
    "\n",
    "    tp = conf[1,1]\n",
    "    tn = conf[0,0]\n",
    "    fp = conf[1,0]\n",
    "    fn = conf[0,1]\n",
    "\n",
    "    precision   = tp / (tp + fp + 1e-9)\n",
    "    recall      = tp / (tp + fn + 1e-9)\n",
    "    sensitivity = tp / (tp + fn + 1e-9)\n",
    "    specificity = tn / (tn + fp + 1e-9)\n",
    "\n",
    "    f1 = (2*precision*recall) / (precision+recall+1e-9)\n",
    "    accuracy = (tp+tn) / (tp+tn+fp+fn + 1e-9)\n",
    "\n",
    "    print '\\tspecificity %.3f' % specificity\n",
    "    print '\\tsensitivty: %.3f' % sensitivity\n",
    "\n",
    "    # AUC\n",
    "    if len(set(ref)) == 2:\n",
    "        auc = sklearn.metrics.roc_auc_score(ref, P)\n",
    "        print '\\t\\tauc:        %.3f' % auc\n",
    "\n",
    "    print '\\taccuracy:   %.3f' % accuracy\n",
    "    print '\\tprecision:  %.3f' % precision\n",
    "    print '\\trecall:     %.3f' % recall\n",
    "    print '\\tf1:         %.3f' % f1\n",
    "\n",
    "    res = {'accuracy':accuracy, 'precision':precision, 'recall':recall, 'f1':f1,\n",
    "           'auc':auc, 'sensitivity':sensitivity, 'specificity':specificity}\n",
    "    return res\n",
    "\n",
    "\n",
    "def classification_results(svm, labels_map, X, Y, task):\n",
    "    # for AUC\n",
    "    P_ = svm.decision_function(X)\n",
    "\n",
    "    # sklearn has stupid-ass changes in API when doing binary classification. make it conform to 3+\n",
    "    if len(labels_map)==2:\n",
    "        m = X.shape[0]\n",
    "        P = np.zeros((m,2))\n",
    "        P[:,0] = -P_\n",
    "        P[:,1] =  P_\n",
    "    else:\n",
    "        P = P_\n",
    "\n",
    "    train_pred = P.argmax(axis=1)\n",
    "\n",
    "    # what is the predicted vocab without the dummy label?\n",
    "    V = labels_map.keys()\n",
    "\n",
    "    print task\n",
    "    res = compute_stats(task, train_pred, P, Y, labels_map)\n",
    "    print '\\n'\n",
    "    return res\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4CVepZOgV9Pw",
    "outputId": "36aa80ff-5742-4b13-9772-0aadc82d2c3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features: 620\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# Fit vectorizer for chartevents features\n",
    "# =========================================\n",
    "vect = DictVectorizer()\n",
    "vect.fit(chartevents_features.values())\n",
    "print 'num_features:', len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "LZf5L3c1V9Px"
   },
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# display informative features\n",
    "# =========================================\n",
    "\n",
    "def classification_analyze(task, vect, clf, labels_map, num_feats=10):\n",
    "    ind2feat =  { i:f for f,i in vect.vocabulary_.items() }\n",
    "\n",
    "    labels = [label for label,i in sorted(labels_map.items(), key=lambda t:t[1])]\n",
    "    coef_ = clf.coef_\n",
    "\n",
    "    informative_feats = np.argsort(coef_)\n",
    "\n",
    "    neg_features = informative_feats[0,:num_feats ]\n",
    "    pos_features = informative_feats[0,-num_feats:]\n",
    "\n",
    "    # display what each feature is\n",
    "    print 'POS %s' % label\n",
    "    for feat in reversed(pos_features):\n",
    "        val = coef_[0,feat]\n",
    "        word = ind2feat[feat]\n",
    "        if val > 1e-4:\n",
    "            print '\\t%-25s: %7.4f' % (word,val)\n",
    "        else:\n",
    "            break\n",
    "    print 'NEG %s' % label\n",
    "    for feat in reversed(neg_features):\n",
    "        val = coef_[0,feat]\n",
    "        word = ind2feat[feat]\n",
    "        if -val > 1e-4:\n",
    "            print '\\t%-25s: %7.4f' % (word,val)\n",
    "        else:\n",
    "            continue\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FSVA9RMoV9Px",
    "outputId": "cf006550-b523-47a4-ac14-9124d160690c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trust': 0, 'mistrust': 1}\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# vectorize task-specific labels\n",
    "# =========================================\n",
    "trust_Y_vect = {'mistrust': 1, 'trust': 0}\n",
    "print trust_Y_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "aR3KBhPoV9Px",
    "outputId": "e961dc68-b5fb-46b3-c756-5667b4d542b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patients: 54510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saadtech/Desktop/py3converted/py2env/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l1', random_state=None, solver='warn',\n",
      "          tol=0.01, verbose=0, warm_start=False)\n",
      "train: noncompliance\n",
      "[[37823   334]\n",
      " [    0     0]]\n",
      "\n",
      "\tspecificity 1.000\n",
      "\tsensitivty: 0.000\n",
      "\t\tauc:        0.712\n",
      "\taccuracy:   0.991\n",
      "\tprecision:  0.000\n",
      "\trecall:     0.000\n",
      "\tf1:         0.000\n",
      "\n",
      "\n",
      "test:  noncompliance\n",
      "[[16207   146]\n",
      " [    0     0]]\n",
      "\n",
      "\tspecificity 1.000\n",
      "\tsensitivty: 0.000\n",
      "\t\tauc:        0.703\n",
      "\taccuracy:   0.991\n",
      "\tprecision:  0.000\n",
      "\trecall:     0.000\n",
      "\tf1:         0.000\n",
      "\n",
      "\n",
      "POS mistrust\n",
      "\t('riker-sas scale', 'agitated'):  0.5512\n",
      "\t('education readiness', 'no'):  0.2707\n",
      "\t('education topic', 'medications'):  0.2591\n",
      "\t('follows commands', 'inconsistently'):  0.1089\n",
      "\t('education barrier', 'other/remarks'):  0.0979\n",
      "\t('pain level', '7-mod to severe'):  0.0818\n",
      "\t('orientation', 'disoriented'):  0.0705\n",
      "\t('education barrier', 'altered loc'):  0.0602\n",
      "\t('orientation', 'oriented x 2'):  0.0480\n",
      "\t('pain level', 'none')   :  0.0410\n",
      "\t('verbal response', '4 confused'):  0.0152\n",
      "\t('restraints evaluated', \"restraint dc'd\"):  0.0036\n",
      "NEG mistrust\n",
      "\t('pain present', 'no')   : -0.0341\n",
      "\t('pain level', 'tolerable'): -0.0754\n",
      "\t('pain level', 'mild ')  : -0.0911\n",
      "\t('orientation', 'unable to assess'): -0.1138\n",
      "\t('support systems', 'children'): -0.1163\n",
      "\t('is the spokesperson the health care proxy', '1'): -0.1180\n",
      "\t('pain present', 'yes')  : -0.1270\n",
      "\t('pain assess method', 'non-verbal cues'): -0.1430\n",
      "\t('verbal response', '1.0 et/trach'): -0.1459\n",
      "\t('skin care', 'done')    : -0.1625\n",
      "\t('support systems', 'spouse'): -0.1719\n",
      "\t('family communication', 'family visited'): -0.1736\n",
      "\t('pain', 'none')         : -0.4253\n",
      "\t('richmond-ras scale', ' 0  alert and calm'): -0.4430\n",
      "\t('state', 'alert')       : -1.0233\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# CLASSIFIER: noncompliance\n",
    "# =========================================\n",
    "noncompliance_cohort = list(set(trust_labels_noncompliance.keys()) & set(chartevents['hadm_id'].values))\n",
    "print 'patients:', len(noncompliance_cohort)\n",
    "\n",
    "# train/test split\n",
    "noncompliance_train_ids, noncompliance_test_ids = data_split(noncompliance_cohort)\n",
    "\n",
    "# select pre-computed features\n",
    "noncompliance_train_features = [chartevents_features[hadm_id] for hadm_id in noncompliance_train_ids]\n",
    "noncompliance_test_features  = [chartevents_features[hadm_id] for hadm_id in noncompliance_test_ids ]\n",
    "\n",
    "# vectorize features\n",
    "noncompliance_train_X = vect.transform(noncompliance_train_features)\n",
    "noncompliance_test_X  = vect.transform(noncompliance_test_features)\n",
    "\n",
    "# select labels\n",
    "noncompliance_train_Y = [trust_Y_vect[trust_labels_noncompliance[hadm_id]] for hadm_id in noncompliance_train_ids]\n",
    "noncompliance_test_Y  = [trust_Y_vect[trust_labels_noncompliance[hadm_id]] for hadm_id in noncompliance_test_ids ]\n",
    "\n",
    "# fit model\n",
    "noncompliance_svm = LogisticRegression(C=0.1, penalty='l1', tol=0.01)\n",
    "noncompliance_svm.fit(noncompliance_train_X, noncompliance_train_Y)\n",
    "print noncompliance_svm\n",
    "\n",
    "# evaluate model\n",
    "classification_results(noncompliance_svm, trust_Y_vect, noncompliance_train_X, noncompliance_train_Y, 'train: noncompliance')\n",
    "classification_results(noncompliance_svm, trust_Y_vect,  noncompliance_test_X,  noncompliance_test_Y, 'test:  noncompliance')\n",
    "\n",
    "# most informative features\n",
    "classification_analyze('noncompliance', vect, noncompliance_svm, trust_Y_vect, num_feats=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "u5IY1rq-V9Py",
    "outputId": "c7349d50-f076-4d3c-9f0e-8444c8cd46fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patients: 997\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l1', random_state=None, solver='warn',\n",
      "          tol=0.01, verbose=0, warm_start=False)\n",
      "train: autopsy\n",
      "[[501 196]\n",
      " [  0   0]]\n",
      "\n",
      "\tspecificity 1.000\n",
      "\tsensitivty: 0.000\n",
      "\t\tauc:        0.594\n",
      "\taccuracy:   0.719\n",
      "\tprecision:  0.000\n",
      "\trecall:     0.000\n",
      "\tf1:         0.000\n",
      "\n",
      "\n",
      "test:  autopsy\n",
      "[[230  70]\n",
      " [  0   0]]\n",
      "\n",
      "\tspecificity 1.000\n",
      "\tsensitivty: 0.000\n",
      "\t\tauc:        0.596\n",
      "\taccuracy:   0.767\n",
      "\tprecision:  0.000\n",
      "\trecall:     0.000\n",
      "\tf1:         0.000\n",
      "\n",
      "\n",
      "POS mistrust\n",
      "\t('restraints evaluated', 'restraintreapply'):  0.0693\n",
      "\t('orientation', 'oriented x 3'):  0.0360\n",
      "NEG mistrust\n",
      "\t('family communication', 'family talked to md'): -0.0041\n",
      "\t('education topic', 'coping'): -0.0220\n",
      "\t('support systems', 'children'): -0.1139\n",
      "\t('pain present', 'no')   : -0.2258\n",
      "\t('side rails', '3 rails up'): -0.2940\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Evaluate mistrust score predicting mortality\n",
    "# ============================================\n",
    "\n",
    "# CLASSIFIER: autopsy\n",
    "\n",
    "autopsy_cohort = list(set(trust_labels_autopsy.keys()) & set(chartevents['hadm_id'].values))\n",
    "print 'patients:', len(autopsy_cohort)\n",
    "\n",
    "# train/test split\n",
    "autopsy_train_ids, autopsy_test_ids = data_split(autopsy_cohort)\n",
    "\n",
    "# select pre-computed features\n",
    "autopsy_train_features = [chartevents_features[hadm_id] for hadm_id in autopsy_train_ids]\n",
    "autopsy_test_features  = [chartevents_features[hadm_id] for hadm_id in autopsy_test_ids ]\n",
    "\n",
    "# vectorize features\n",
    "autopsy_train_X = vect.transform(autopsy_train_features)\n",
    "autopsy_test_X  = vect.transform(autopsy_test_features)\n",
    "\n",
    "# select labels\n",
    "autopsy_train_Y = [trust_Y_vect[trust_labels_autopsy[hadm_id]] for hadm_id in autopsy_train_ids]\n",
    "autopsy_test_Y  = [trust_Y_vect[trust_labels_autopsy[hadm_id]] for hadm_id in autopsy_test_ids ]\n",
    "\n",
    "# fit model\n",
    "autopsy_svm = LogisticRegression(C=0.1, penalty='l1', tol=0.01)\n",
    "autopsy_svm.fit(autopsy_train_X, autopsy_train_Y)\n",
    "print autopsy_svm\n",
    "\n",
    "# evaluate model\n",
    "classification_results(autopsy_svm, trust_Y_vect, autopsy_train_X, autopsy_train_Y, 'train: autopsy')\n",
    "classification_results(autopsy_svm, trust_Y_vect,  autopsy_test_X,  autopsy_test_Y, 'test:  autopsy')\n",
    "\n",
    "# most informative features\n",
    "classification_analyze('trust', vect, autopsy_svm, trust_Y_vect, num_feats=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "WtoF4ZrEV9Py",
    "outputId": "dad65929-8ff5-482d-fc4d-aa2bc18b5c90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: noncompliance scores\n",
      "DONE: autopsy scores\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# Predict scores for all patients and save to file\n",
    "# ================================================\n",
    "\n",
    "# ordering of all chartevents features\n",
    "chartevents_ids = set(chartevents['hadm_id'].values)\n",
    "chartevents_X = vect.transform([chartevents_features[hadm_id] for hadm_id in chartevents_ids])\n",
    "\n",
    "# Save ranking (i.e. confidence from trust classifier) of all patients on the noncompliance metric\n",
    "with open('data/mistrust_noncompliant.pkl', 'wb') as f:\n",
    "    noncompliance_scores = dict(zip(chartevents_ids,noncompliance_svm.decision_function(chartevents_X)))\n",
    "    pickle.dump(noncompliance_scores, f)\n",
    "print 'DONE: noncompliance scores'\n",
    "\n",
    "# Save ranking (i.e. confidence from trust classifier) of all patients on the autopsy metric\n",
    "with open('data/mistrust_autopsy.pkl', 'wb') as f:\n",
    "    autopsy_scores = dict(zip(chartevents_ids,autopsy_svm.decision_function(chartevents_X)))\n",
    "    pickle.dump(autopsy_scores, f)\n",
    "print 'DONE: autopsy scores'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL28x1QmV9Pz"
   },
   "source": [
    "<h1>Sentiment Analysis as Mistrust Proxy</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "4-4fBBjUV9Pz",
    "outputId": "c1f713a1-3299-4e85-87e2-5b471dd71f64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59568it [02:19, 425.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sa: 52726\n",
      "DONE: negative sentiment scores\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# Sentiment Analysis\n",
    "# ================================================\n",
    "from pattern.en import sentiment\n",
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "disch_query = \\\n",
    "\"\"\"\n",
    "select distinct n.hadm_id,n.category,n.text,n.chartdate,n.charttime\n",
    "from mimiciii.noteevents n\n",
    "where iserror IS NULL --this is null in mimic 1.4, rather than empty space\n",
    "and hadm_id IS NOT NULL\n",
    "and category = 'Discharge summary'\n",
    ";\n",
    "\"\"\"\n",
    "disch = pd.read_sql_query(disch_query, con)\n",
    "\n",
    "\n",
    "sentiments = {}\n",
    "#for hadm_id in tqdm.tqdm(bw_eol_cohort['hadm_id'].values):\n",
    "for _,row in tqdm.tqdm(disch.iterrows()):\n",
    "    hadm_id = row.hadm_id\n",
    "    text = row.text\n",
    "\n",
    "    # Returns a (polarity, subjectivity)-tuple.\n",
    "    sa = sentiment(text.split())\n",
    "    #sa = sentiment(text)\n",
    "    #print sa\n",
    "    sentiments[hadm_id] = sa[0]\n",
    "    #break\n",
    "\n",
    "scores = np.array(sentiments.values())\n",
    "mu = scores.mean()\n",
    "std = scores.std()\n",
    "sentiments = {k:-(v-mu)/std for k,v in sentiments.items()}\n",
    "\n",
    "print 'sa:', len(sentiments)\n",
    "\n",
    "with open('data/neg_sentiment.pkl', 'wb') as f:\n",
    "    pickle.dump(sentiments, f)\n",
    "print 'DONE: negative sentiment scores'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tApMBkUGV9Pz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
